{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cbb7bf4",
   "metadata": {},
   "source": [
    "# Lectura 9\n",
    "\n",
    "## RafaCastle\n",
    "\n",
    "## 9.1 Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fbcebc",
   "metadata": {},
   "source": [
    "Consideremos el siguirnyr problema de clasificación:\n",
    "\n",
    "Se tiene un conjunto de datos ${(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})}$, donde $L$ es el número de capas ($L=4$) y $s_l$ es el número de unidades (sin contar los sesgos) en la capa $l$.\n",
    "\n",
    "![Title](Imágenes/9-1-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4631d8",
   "metadata": {},
   "source": [
    "En este ejemplo $s_1=3$, $s_2=5$, $s_3=5$ y $s_4=4$. Consideraremos 2 tipos de problemas de clasificación:\n",
    "\n",
    " - Clasificación binaria: Donde solo hay 2 opciones, que $x$ esté dentro de la catagoría o no, por lo que $y=0,1$, y las redes neuronales tienen solo una unidad de salida.\n",
    " - Clasificación multi-clase: Si se tienen $k$ categorías entonces $y \\in R^{k}$ por ejemplo $y=[1,0,0,0]$ o $y=[0,1,0,0]$, etc. Por lo que la función hipótesis cumplirá $h_\\theta (x) \\in R^{k}$ y la última capa de la red neuronal tendrá siempre $k$ unidades, osea $s_L = k-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcf198d",
   "metadata": {},
   "source": [
    "la cost function que se utilizó en la regresión logística es un caso particular de la que se utiliza en una red neuronal, como se ve a continuación, la notación $(h_\\Theta (x))_i$ se refiere a la i-ésima entrada del vector $h_\\Theta$, recodemos que $h_\\Theta \\in R^k$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104eb0e",
   "metadata": {},
   "source": [
    "![Title](Imágenes/9-1-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43eefbe",
   "metadata": {},
   "source": [
    "El segundo término es el término de regularización. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0091556",
   "metadata": {},
   "source": [
    "## 9.2 Algoritmo backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab697a4",
   "metadata": {},
   "source": [
    "En esta sección veremos como minimizar la función $J(\\Theta)$ mediante el algoritmo backpropagation, para esto necesitamos computar los valores \n",
    "\n",
    "$$\n",
    "J(\\Theta) \\hspace{1cm} y \\hspace{1cm}  \\frac{\\partial}{\\partial \\Theta_{ij}^{(l)}} J(\\Theta)\n",
    "$$. \n",
    "\n",
    "Consideremos un ejemplo, dado un conjunto de entrenamiento $(x,y)$ se tiene la siguiente red neuronal:\n",
    "\n",
    "![Title](Imágenes/9-2-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39167fe7",
   "metadata": {},
   "source": [
    "ahora, para dar una explicación intuitiva definamos el parámetro $\\delta_j^{(l)}$ que denote el error del nodo $j$ en la capa $l$. Para cada valor de salida se tendría (en la capa 4):\n",
    "\n",
    "$$\n",
    "\\delta_j^{(4)} = a_j^{(4)} -y_j \n",
    "$$\n",
    "\n",
    "al darle un tratamiento vectorial a la ecuación anterior se puede reescribir de la forma:\n",
    "\n",
    "$$\n",
    "\\delta^{(4)} = a^{(4)} -y\n",
    "$$\n",
    "\n",
    "para obtener el error en las capas $l=2,3$ se tiene la siguiente expresión recursiva:\n",
    "\n",
    "$$\n",
    "\\delta^{(l)} = (\\Theta^{(l})^T \\delta^{(l+1)} \\cdot g'(z^{(l)})\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$\n",
    "g'(z^{(l)}) = a^{(l)} \\cdot (1-a^{(l)})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6923f",
   "metadata": {},
   "source": [
    "Claramente no hay un término $\\delta^{(1)}$ ya que son los valores de entrada. \n",
    "\n",
    "Es posible probar matemáticamente que para la expresión sin regularización ($\\lambda = 0$) se cumple:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\Theta_{ij}^{(l)}} J (\\Theta) = a^{(l)}_j \\delta^{(l+1)}_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b82fa1",
   "metadata": {},
   "source": [
    "### Algortimo Backpropagation\n",
    "\n",
    "Tomemos ahora sí un conjunto de entrenamiento $\\{ (x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), ... , (x^{(m)}, y^{(m)}) \\}$, el primer paso de algoritmo es hacer \n",
    "\n",
    "$$\n",
    "\\Delta_{ij}^{(l)} = 0\n",
    "$$\n",
    "\n",
    "para todas $l,i,j$, esta expresión se definirá más adelante y nos será útil más adelante para computar $\\frac{\\partial}{\\partial \\Theta_{ij}^{(l)}} J (\\Theta)$. Intuitivamente el algoritmo realiza lo siguiente:\n",
    "\n",
    "for $i$ in range(1,$m$):\n",
    "\n",
    " - $a^{(1)}=x^{(i)}$\n",
    " - determinar $a^{(l)}$ para $l = 2,3,...,L$\n",
    " - usando $y^{(L-1)}$ computar $\\delta^{(L)} = a^{(L)} - y^{(i)}$\n",
    " - computar $\\delta^{(L-1)}, \\delta^{(L-2)}, ..., \\delta^{(2)}$\n",
    " - $\\Delta_{ij}^{(l)} := \\Delta_{ij}^{(l)} + a^{(l)}_j \\delta^{(l+1)}_i$\n",
    " \n",
    "Tras esto se define el siguiente parámetro:\n",
    "\n",
    "$$\n",
    "D_{ij}^{(l)} := \\frac{1}{m} \\left\\{ \\begin{array}{cc}\n",
    "\\Delta_{ij}^{(l)} + \\lambda \\Theta_{ij}^{(l)} & \\text{ si } j \\neq 0 \\\\\n",
    "\\Delta_{ij}^{(l)} & \\text{ si } j = 0\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "donde \n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\Theta_{ij}^{(l)}} J(\\Theta) = D_{ij}^{(l)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc6086c",
   "metadata": {},
   "source": [
    "## 9.3 Intuición del algoritmo Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d4d1d9",
   "metadata": {},
   "source": [
    "En esta sección se analizan los pasos del algoritmo pero no se da información nueva sobre el mismo, por lo que no haré notas de esta sección, recomiendo ver el [vídeo](https://www.youtube.com/watch?v=mOmkv5SI9hU) ya que resulta bastante ilustrativo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e8b1b",
   "metadata": {},
   "source": [
    "## 9.4 Desenrollando los parámetros de interpretación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18537d",
   "metadata": {},
   "source": [
    "Se explica el código en octave, tampoco haré notas de esta sección."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c8c929",
   "metadata": {},
   "source": [
    "## 9.5 Verificación del gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37cd96",
   "metadata": {},
   "source": [
    "Como algoritmo, backpropagation puede ser complejo de implementar por su gran cantidad de detalles, además muchos bugs pueden ser pasados por alto. Es por esto que surge la idea de verificar el gradiente, de modo que estos errores sean visibles. Veamos la idea.\n",
    "\n",
    "Consideremos una función $J(\\Theta)$\n",
    "\n",
    "![Title](Imágenes/9-5-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec046056",
   "metadata": {},
   "source": [
    "Tomemos un punto $\\theta$ en el eje horizontal y un valor pequeño ($\\approx 10^{-4}$) $\\epsilon > 0$, por nociones básicas de cálculo, sabemos que es posible aproximar el valor de la derivada de $J$ en este punto por la ecuación\n",
    "\n",
    "$$\n",
    "\\frac{d}{d \\theta} J(\\theta) \\approx \\frac{J(\\theta + \\epsilon) - J(\\theta - \\epsilon)}{2 \\epsilon}\n",
    "$$\n",
    "\n",
    "![Title](Imágenes/9-5-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320cf4db",
   "metadata": {},
   "source": [
    "De esta manera nos podemos dar una idea aproximada del valor del gradiente en $\\theta$.\n",
    "\n",
    "Ahora tomemos $\\theta \\in R^{n}$ tal que $\\theta = [\\theta_1, \\theta_2, ..., \\theta_n]$. Podemos usar una idea similar para aproximar las derivadas parciales y obtener el gradiente:\n",
    "\n",
    "![Title](Imágenes/9-5-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89e1b9",
   "metadata": {},
   "source": [
    "Así se puede aproximar el valor de la parcial de $J$ con respecto a alguno de los parámetros $\\theta_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d77c1",
   "metadata": {},
   "source": [
    "## 9.6 Inicialización aleatoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d89a49",
   "metadata": {},
   "source": [
    "Cuando se corre un algoritmo como el gradient descent es necesario darle valores iniciales a los parámetros $\\theta$. A diferencia de la regresión logística, en una red neuronal no es buena opción que estos valores iniciales sean todos 0. Esto es porque las unidades en la capa oculta serían iguales, como se muestra en el siguiente ejemplo:\n",
    "\n",
    "![Title](Imágenes/9-6-1.png)\n",
    "\n",
    "En el ejemplo anterior se muestra como, si todos los pesos fueran 0, tanto $a_1^{(2)}$ como $a_2^{(2)}$ van a computar lo mismo, o sea que $a_1^{(2)} = a_2^{(2)}$, por lo que $\\delta_1^{(2)} = \\delta_2^{(2)}$, por lo que se cumpliría:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\Theta_{01} ^{(1)}} J (\\Theta) = \\frac{\\partial}{\\partial \\Theta_{02} ^{(1)}} J (\\Theta) \\hspace{1cm} \\Rightarrow \\hspace{1cm} \\Theta_{01} ^{(1)} = \\Theta_{02} ^{(1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f87084",
   "metadata": {},
   "source": [
    "Por lo que, aún pasando varias iteraciones, las dos unidades de la capa oculta seguirán computando los mismos valores. De hecho esto se cumpliría aún cuando existan muchas unidades en la capa oculta, todas seguirían computando los mismos valores. Esta complicación se resuelve con la inicialización aleatoria, que consiste en darle un valor aleatorio inicial a $\\Theta_{ij}^{(l)}$ entre $[-\\epsilon, \\epsilon]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89356845",
   "metadata": {},
   "source": [
    "## 9.7 Juntando lo aprendido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74462e",
   "metadata": {},
   "source": [
    "Para configurar una red neuronal se debe considerar primero la arquitectura de la red, es decir, la forma de ésta. Lo primero que debe considerarse es la cantidad de capas ocultas y las unidades que cada una de éstas tendra, las unidades de entrada y de salida están dadas por el contexto del problema. \n",
    "\n",
    "Por default se recomienda tomar únicamente una capa oculta, si se toma más de una capa oculta entonces la configuración más estándar propondría tener la misma cantidad de unidades en cada capa oculta. Generalmente una mayor cantidad de capas ocultas implicará un mejor resultado, pero tendrá un mayor costo computacional. La cantidad de unidades en las capas ocultas generalmente es un número un poco menor al doble de unidades en la capa de entrada. \n",
    "\n",
    "Los pasos para entrenar a una red neuronal son:\n",
    "\n",
    "1. Iniciar aleatoriamente los pesos\n",
    "2. Implementar forward propagation para obtener $h_\\Theta (x^{(i)} )$ para cada $x^{(i)}$.\n",
    "3. Implementar $J (\\Theta)$\n",
    "4. Implementar back propagation para computar las derivadas parciales $\\frac{\\partial}{\\partial \\Theta_{jk} ^{(1)}} J (\\Theta)$\n",
    "5. Comparar los resultados de $\\frac{\\partial}{\\partial \\Theta_{jk} ^{(1)}} J (\\Theta)$ obtenido mediante back propagation vs el estimado numérico del gradiente de $J(\\Theta)$ usando el chequeo del gradiente\n",
    "6. Usar gradient descent o algún método de optimización avanzada para minimizar $J(\\Theta)$ como una función de parámetros $\\Theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627a1e7",
   "metadata": {},
   "source": [
    "## 9.8 Ejemplo de manejo automático"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b735b",
   "metadata": {},
   "source": [
    "En esta sección solo se muestra un vídeo de un algorimto que esta aprendiendo a manejar un vehículo por medio de redes neuronales, recomiendo ver el [vídeo](https://www.youtube.com/watch?v=ppFyPUx9RIU&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=57)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
