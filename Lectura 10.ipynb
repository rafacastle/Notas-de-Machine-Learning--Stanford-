{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96f506e",
   "metadata": {},
   "source": [
    "# Lectura 10\n",
    "## RafaCastle\n",
    "## 10.1 Decidiendo próximos intentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355644b",
   "metadata": {},
   "source": [
    "En estas secciones se buscará transmitir las mejores recomendaciones para hacer más eficiente a un sistema de aprendizaje automático sin estar probando configuraciones aleatorias que pueden no llevar a ningún resultado. \n",
    "\n",
    "Para esto seguiremos usando el ejemplo de la predicción del precio de una casa. Supongamos que se ha implemendado una regresión lineal regularizada para predecir un precio:\n",
    "\n",
    "$$\n",
    "J(\\Theta) = \\frac{1}{2m} \\left[ \\sum_{i=1}^m (h_\\theta (x^{(i)}) -y^{(i)})^2 + \\lambda \\sum_{j=1}^m \\theta^2_j \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1bed89",
   "metadata": {},
   "source": [
    "Ahora imaginémos que al probar la hipótesis en un conjunto nuevo, se observan errores inaceptáblemente grandes en las predicciones. ¿Qué se debería hacer ahora?\n",
    "\n",
    "- Conseguir más ejemplos de entrenamiento\n",
    "- Tomar atributos más pequeños $x_1, x_2, ..., x_{100}$\n",
    "- Tomás más atributos\n",
    "- Agregar atributos polinómicos ($x_1^2, x_2^2,$ etc)\n",
    "- Incrementar o decrementar $\\lambda$\n",
    "\n",
    "Para descartar las opciones que no aportarán una mejora al modelo existe una técnica simple llamada diagnóstico de aprendizaje de máquina. Esta técnica puede correrse para saber qué es lo que está y no está funcionando en el algoritmo de aprendizaje, de esta forma se puede mejorar su rendimiento sin intentar opciones que solo hagan perder el tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8cbbe6",
   "metadata": {},
   "source": [
    "## 10.2 Evaluando una hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a7d03",
   "metadata": {},
   "source": [
    "Para evaluar una hipótesis se debe dividir a un conjunto de datos en un conjunto de prueba y otro de entrenamiento generalmente en una proporción $30\\% - 70\\%$ respectivamente. Una vez que el algoritmo se a entrenado con los datos de entrenamiento, se pone a prueba con los datos de prueba. Supongamos que el conjunto de entrenamiento tiene $m$ datos y el de prueba $m_p$. En ese caso, si se quiere evaluar una hipótesis de regresión lineal se utiliza la ecuación:\n",
    "\n",
    "$$\n",
    "J_p (\\theta)=\\frac{1}{2m_p} \\sum_{i=1}^{m_p}(h_\\theta (x_p ^{(i)})-y_p ^{(i)})^2\n",
    "$$\n",
    "\n",
    "donde $x_p$ y $y_p$ son los datos del conjunto de prueba. \n",
    "\n",
    "Para el caso de un problema de clasificación, con regresión logística se tiene:\n",
    "\n",
    "$$\n",
    "J_p (\\theta)=\\frac{1}{m_p} \\sum_{i=1}^{m_p} (y_p ^{(i)} \\log [h_\\theta (x_p ^{(i)})] + (1- y_p ^{(i)})\\log [h_\\theta (x_p ^{(i)})] )\n",
    "$$\n",
    "\n",
    "Existe otra prueba para los problemas de clasificación dada por:\n",
    "\n",
    "$$\n",
    "err(h_\\theta (x),y) = \\left\\{ \n",
    "\\begin{array}[ccc] \\\\\n",
    "    1 &\\text{si} & h_\\theta(x) \\geq 0.5 \\text{ && } y=0 \\\\\n",
    "    0 &\\text{si} & h_\\theta(x) < 0.5 \\text{ && } y=1\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "asi, la prueba de error $p_e$ se calcula de la forma:\n",
    "\n",
    "$$\n",
    "p_e = \\frac{1}{m_p} \\sum_{i=1}^{m_p} err(h_\\theta (x_p^{(i)}),y_p^{(i)}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c4e97",
   "metadata": {},
   "source": [
    "## 10.3 Selección de modelos y de conjuntos de entrenamiento/validación/prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbff70a",
   "metadata": {},
   "source": [
    "Para seleccionar cual es el mejor modelo para predecir una variable en un conjunto de datos se suele dividir el conjunto en 3 subconjuntos denominados:\n",
    "\n",
    "- Conjunto de prueba $60\\%$\n",
    "- Conjunto de entrenamiento $20\\%$\n",
    "- Conjunto cross validation $20\\%$\n",
    "\n",
    "De esta forma se selecciona al mejor modelo evaluando la función \n",
    "\n",
    "$$\n",
    "J_{cv} (\\theta)=\\frac{1}{2m_{cv}} \\sum_{i=1}^{m_{cv}}(h_\\theta (x_{cv} ^{(i)})-y_{cv} ^{(i)})^2\n",
    "$$\n",
    "\n",
    "y tomando el vector $\\theta$ que arroje los valores $J(\\theta)$ más pequeños. El subíndice $cv$ se refiere a los datos que están en el subconjunto cross validation y $m_{cv}$ es la cantidad de elementos en dicho conjunto.  Haciendo esto, el subconjunto de prueba puede apartarse únicamente para obtener el error del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e161d",
   "metadata": {},
   "source": [
    "## 10.4 Diagnosticando el sesgo vs la varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d1e67c",
   "metadata": {},
   "source": [
    "Cuando un algoritmo no haga una buena predicción, generalmente se debe a un sesgo o a una varianza grande, es decir, a un problema de overfitting o de underfitting. \n",
    "\n",
    "![Title](Imágenes/10-4-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aefa86",
   "metadata": {},
   "source": [
    "Es claro que mientras de mayor grado sea el polinomio de la función hipótesis, será mayor el overfitting. Si se grafica el error vs el grado del polinomio para las funciones $J_{cv}$ (subconjunto cross validation) y $J_t$ (subonjunto de entrenamiento) se obitene una gráfica como la siguiente:\n",
    "\n",
    "![Title](Imágenes/10-4-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116fa400",
   "metadata": {},
   "source": [
    "En esta gráfica, es claro que si el polinomio tiene un grado pequeño, se trata de un problema de alto sesgo, es decir:\n",
    "\n",
    "- $J_t$ tiene un valor alto\n",
    "- $J_{cv} \\approx J_t$\n",
    "\n",
    "si el polinomio tiene un grado demasiado alto, se trata de un problema de alta varianza, es decir:\n",
    "\n",
    "- $J_t$ será pequeña\n",
    "- $J_{cv} \\gt \\gt J_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c86915",
   "metadata": {},
   "source": [
    "## 10.5 Regularización y sesgo/varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82254c",
   "metadata": {},
   "source": [
    "Si se tiene una función hipótesis de un grado alto (en este caso grado 4), debe escogerse un valor $\\lambda$ justo, es decir, que no anule los valores de $\\theta_1$, $\\theta_2$, etc (caso de unferfitting). Pero que en efecto regularice a la función sin caer en el overfitting.\n",
    "\n",
    "![Title](Imágenes/10-5-1.png)\n",
    "\n",
    "La pregunta más natural es, ¿Cómo puede obtenerse el valor correcto de $\\lambda$?\n",
    "\n",
    "Una forma práctica de obtener el mejor valor de $\\lambda$ es probar distitnos valores tales que $\\lambda = 0, 0.01, 0.02, ..., 10$ y minimizar la función $J(\\Theta)$ para obtener un conjunto de valores $\\Theta^{(\\lambda)}$. Ya obtenidos estos valores se escoge el vector $\\Theta^{(k)}$ para el cual $J_{cv} (\\Theta^{(k)})$ sea mínimo. Con este vector se puede finalmente hacer la prueba $J_{t} (\\Theta^{(k)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c87fe",
   "metadata": {},
   "source": [
    "Al graficar las funciones $j_{cv} (\\Theta)$ y $j_{t} (\\Theta)$ para distintos valores de $\\lambda$, es notorio que el punto donde ambas funciones llegan a un mejor acuerdo es en un valor de lambda mediano. En dicho punto se alcanza un mínimo en la función $J_{cv}$ y el valor de la función $J_t$ es aceptablemente bajo.  \n",
    "\n",
    "![Title](Imágenes/10-5-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c880ad",
   "metadata": {},
   "source": [
    "## 10.6 Curvas de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc4745",
   "metadata": {},
   "source": [
    "Las curvas de aprendizaje son una herramienta útil para diagnisticar el tipo de problema que presenta un modelo de apredizaje. Par agraficarlas se toman las funciones $J_{cv}$ y $J_t$, además se reduce artificialmente el tamaño del conjunto, es decir se retiran algunos datos del mismo. Tomemos el siguiente ejemplo:\n",
    "\n",
    "![Title](Imágenes/10-6-0.png)\n",
    "\n",
    "En este ejemplo es claro que la función hipótesis hara buenas predicciones para valores pequeños de $m$ (en el conjunto de entrenamiento), sin embargo al ir aumentando estos valores, la función incrementará su error.\n",
    "\n",
    "Por otro lado, conforme incremente $m$, decrecerá el número de errores en la función de validación. Ambas funciones tendrán comportamientos distintos dependiendo si se trata de un problema de alta varianza o alto sesgo, comose mostrará a continuación.\n",
    "\n",
    "![Title](Imágenes/10-6-2.png)\n",
    "\n",
    "Para un algoritmo de aprendizaje que tiene mucho sesgo, no será útil agregar más datos al conjunto.\n",
    "\n",
    "![Title](Imágenes/10-6-3.png)\n",
    "\n",
    "Para un algoritmo de aprendizaje que tiene mucha varianza, puede ser útil agregar más datos al conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92561f0",
   "metadata": {},
   "source": [
    "## 10.7 Decidiento las próximas acciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c727498",
   "metadata": {},
   "source": [
    "Supongamos que se ha implementado una regresión lineal regularizada para predecir el precio de una casa. Sin embargo, cuando se prueba la hipótesis en un nuevo conjunto, se encuentran errores inaceptables en la predicción. ¿Qué se debería intentar a continuación?\n",
    "\n",
    "- Añadir más datos de entrenamiento (varianza alta)\n",
    "- Hacer más pequeños los atributos (varianza alta)\n",
    "- Añadir atributos (sesgo alto)\n",
    "- Añadir atributos polinómicos ($x_1^2, x_2^2$, etc) (sesgo alto)\n",
    "- Aumentar $\\lambda$ (sesgo alto)\n",
    "- Disminuir $\\lambda$ (varianza alta)\n",
    "\n",
    "Por otro lado, una red neuronal pequeña (figura de la izquerda) tiende más a tener problemas de underfitting pero es más barata en términos computacionales. Una red neuronal larga (figura de la derecha) tiende más a tener problemas de overfitting y es computacionalmente más costosa, al usar regularización puede controlarse el problema del overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
